# ConfiguraciÃ³n de Variables de Entorno para Testing Local

## ğŸš€ Setup RÃ¡pido (< 2 minutos)

### 1. Copia el archivo de ejemplo
```bash
cp .env.example .env.local
```

### 2. ObtÃ©n una API key de Gemini (GRATIS)

1. Ve a [Google AI Studio](https://aistudio.google.com/app/apikey)
2. Haz clic en "Create API Key"
3. Copia la key que empieza con `AIza...`

### 3. Agrega la key a `.env.local`

Abre `.env.local` y reemplaza:

```bash
LLM_API_KEY_GEMINI=AIzaSyC-tu-key-real-aqui-ABC123xyz
```

### 4. Prueba que funcione

```bash
npm run dev
```

Abre en tu navegador:
- **PÃ¡gina de prueba**: http://localhost:3000/test-llm
- **Generador completo**: http://localhost:3000/sam/generator

---

## ğŸ” Verificar configuraciÃ³n

### OpciÃ³n 1: PÃ¡gina de test (recomendado)
Visita http://localhost:3000/test-llm para ver:
- âœ… QuÃ© proveedores estÃ¡n configurados
- ğŸ§ª Probar generaciÃ³n en vivo
- ğŸ“‹ Instrucciones paso a paso

### OpciÃ³n 2: API directa
```bash
curl http://localhost:3000/api/test-llm
```

DeberÃ­a responder:
```json
{
  "status": "ok",
  "llmAvailable": true,
  "providers": {
    "gemini": true,
    "openai": false,
    ...
  }
}
```

### OpciÃ³n 3: Test de generaciÃ³n
```bash
curl -X POST http://localhost:3000/api/test-llm \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Hola, soy un docente chileno"}'
```

---

## ğŸŒ Deployment en Vercel

1. Ve a tu proyecto en Vercel: https://vercel.com/carlosvergara-chiles-projects/sam-applive
2. Settings â†’ Environment Variables
3. Agrega **una o mÃ¡s** de estas variables:

```
LLM_API_KEY_GEMINI = AIzaSyC-tu-key-aqui
```

4. Scope: **Production, Preview, Development** (todas)
5. Save
6. Redeploy el proyecto

---

## ğŸ“š Nombres alternativos soportados

El sistema busca automÃ¡ticamente estas variantes:

**Gemini**:
- `LLM_API_KEY_GEMINI`
- `GOOGLE_API_KEY`
- `GEMINI_API_KEY`

**OpenAI**:
- `LLM_API_KEY_OPENAI`
- `OPENAI_API_KEY`

**DeepSeek**:
- `LLM_API_KEY_DEEPSEEK`
- `DEEPSEEK_API_KEY`

**Anthropic**:
- `LLM_API_KEY_ANTHROPIC`
- `ANTHROPIC_API_KEY`

**Perplexity**:
- `LLM_API_KEY_PERPLEXITY`
- `PERPLEXITY_API_KEY`

---

## âš ï¸ Problemas comunes

### "No LLM API keys found"
- Verifica que copiaste la key completa (no debe tener espacios)
- Reinicia el servidor despuÃ©s de agregar la key (`npm run dev`)
- En Vercel, asegÃºrate de hacer redeploy despuÃ©s de agregar variables

### "Gemini API error: 404"
- El endpoint cambiÃ³ a `v1beta` (ya estÃ¡ corregido en el cÃ³digo)
- Usa el modelo `gemini-1.5-flash-latest`

### "Rate limit exceeded"
- Gemini free tier: 15 requests/minuto
- Espera 1 minuto y reintenta
- O agrega otra API key como fallback (OpenAI, DeepSeek, etc.)

---

## ğŸ¯ Siguiente paso

Una vez configurado, prueba el generador completo:
http://localhost:3000/sam/generator

DeberÃ­a generar contenido educativo REAL en espaÃ±ol, no stubs.
